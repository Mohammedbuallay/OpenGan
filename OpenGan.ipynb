{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenGan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGKnrUlJLCQw",
        "colab_type": "text"
      },
      "source": [
        "# Connect to Extrernal source of database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7kyV5XV3tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "c6dec718-c5b0-4f42-ad29-6e156655d064"
      },
      "source": [
        "#@title After exciting this cell you Have to connect it with You Google Drive. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltpzhqQOB_FN",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Define the Hyper-Parameters\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.random import normal\n",
        "\n",
        "image_height = 256 #@param {type:\"integer\"} \n",
        "image_width = 256 #@param {type:\"integer\"}\n",
        "filters = 64 #@param {type:\"integer\"}\n",
        "output_stride = 16 #@param {type:\"integer\"}\n",
        "height_output = image_height // output_stride \n",
        "width_output = image_width // output_stride\n",
        "batch_size = 32 #@param {type:\"integer\"}\n",
        "latent_dim = 100 #@param {type:\"integer\"}\n",
        "\n",
        "display_noise = normal(shape=[16, latent_dim], mean=0, stddev=1)\n",
        "w_init = tf.initializers.glorot_uniform()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRt0mSbRc45X",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Now we will check the GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "somhpAApbFpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "cellView": "form",
        "outputId": "32a6c8e1-6aa0-4763-b206-0c6f3b5965e2"
      },
      "source": [
        "#@title Preprocess the data and define model paths \n",
        "from tensorflow.image import resize,decode_png\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from tensorflow.io import read_file\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img \n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import cv2,os\n",
        "\n",
        "Main_folder_path = \"old/new_idea_test\" #@param {type:\"string\"}\n",
        "os.chdir(os.path.join(\"/content/drive/My Drive\",Main_folder_path))\n",
        "\n",
        "Augmentation_flag = False #@param {type: \"boolean\"} \n",
        "Augmentation_folder = \"path\" #@param {type:\"string\"}\n",
        "images_path = \"ll\" #@param {type:\"string\"}\n",
        "\n",
        "############################################################# Augmentation part\n",
        "def Augment_images(image_file):\n",
        "  datagen = ImageDataGenerator(zoom_range=0.15,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,\thorizontal_flip=True, vertical_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "  aug_img = load_img(os.path.join(images_path,image_file)) \n",
        "  aug_img = img_to_array(aug_img)\n",
        "  aug_img = aug_img.reshape((1,) + x.shape) \n",
        "\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1,save_to_dir='new', save_prefix='image_file', save_format='jpg'):\n",
        "      i += 1\n",
        "      if i > 50: break\n",
        "\n",
        "if Augmentation_flag:\n",
        "  for image_name in os.listdir(\"ll\"):   \n",
        "      print (\"Augmenting... Image name: \"+image_name)\n",
        "      Augment_images(i)\n",
        "\n",
        "############################################################# Preprocessing\n",
        "def data_load(images_path):\n",
        "    img = resize(decode_png(read_file(images_path)), size=[image_height, image_width])[..., :3]\n",
        "    img /= 127.5\n",
        "    img -= 1\n",
        "    return img\n",
        "\n",
        "image_list = glob(images_path+'/*.jpg')\n",
        "print(len(image_list),' images Found in the folder')\n",
        "\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(image_list)\n",
        "image_dataset = image_dataset.shuffle(buffer_size=10240)\n",
        "image_dataset = image_dataset.map(data_load, num_parallel_calls=AUTOTUNE)\n",
        "image_dataset = image_dataset.batch(batch_size)\n",
        "image_dataset = image_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "model_folders = \"model_files\" #@param {type:\"string\"}\n",
        "generator_weights = \"no_model\" #@param {type:\"string\"}\n",
        "discriminator_weights = \"no_model\" #@param {type:\"string\"}\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "52  images Found in the folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNRqS7bEoBgy",
        "colab_type": "text"
      },
      "source": [
        "#Making the Model -Image is needed-\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBsjmdozXVNW",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Build The Model Dynamically Based on The Image Dimensions and Training the model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Activation,Reshape,Input,Dense,LeakyReLU,Conv2D,ReLU,BatchNormalization,Conv2DTranspose\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.random import normal\n",
        "\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import ones_like,zeros_like,GradientTape,clip_by_value\n",
        "from tensorflow.summary import scalar\n",
        "\n",
        "def deconv_block(input_tensor, num_filters, kernel_size, strides, bn=True):\n",
        "    x = Conv2DTranspose(filters=num_filters, kernel_initializer=w_init, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False if bn else True)(input_tensor)\n",
        "    if bn:\n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block(input_tensor, num_filters, kernel_size, padding='same', strides=2, bn=True, activation=True):\n",
        "    x = Conv2D(filters=num_filters, kernel_initializer=w_init, kernel_size=kernel_size, padding=padding, strides=strides, use_bias=False if bn else True)(input_tensor)\n",
        "    if bn:\n",
        "        x = BatchNormalization()(x)\n",
        "    if activation:\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "def build_generator(latent_dim=100):\n",
        "    f = [2**i for i in range(5)][::-1]\n",
        "    noise = Input(shape=(latent_dim,), name='generator_noise_input')\n",
        "    x = Dense(f[0] * filters * height_output * width_output)(noise)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Reshape(target_shape=[height_output, width_output, 16 * filters])(x)\n",
        "    for i in range(1, 5):\n",
        "        x = deconv_block(x,num_filters=f[i] * filters,kernel_size=5,strides=2,bn=True)\n",
        "    x = deconv_block(x, num_filters=3,kernel_size=3,strides=1,bn=False)\n",
        "    fake_output = Activation('tanh', name='generator_output')(x)\n",
        "    return Model(inputs=[noise],outputs=[fake_output],name='Generator')\n",
        "\n",
        "\n",
        "def build_discriminator():\n",
        "    image_input = Input(shape=[image_height, image_width, 3], name='discriminator_image_input')\n",
        "    f = [2**i for i in range(4)]\n",
        "    x = conv_block(image_input, num_filters=f[0] * filters, kernel_size=5, strides=2, bn=False)\n",
        "    for i in range(1, 4):\n",
        "        x = conv_block(x, num_filters=f[i] * filters, kernel_size=5, strides=2, bn=True)\n",
        "    x = conv_block(x, num_filters=1, kernel_size=height_output, padding='valid', strides=1, bn=False, activation=False)\n",
        "    classification_logits = Reshape(target_shape=[1])(x)\n",
        "    return Model(inputs=[image_input], outputs=[classification_logits], name='Discriminator')\n",
        "\n",
        "generator = build_generator(latent_dim)\n",
        "generator.summary()\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n",
        "\n",
        "if not (generator_weights == \"no_model\" or discriminator_weights == \"no_model\") : \n",
        "  generator.load_weights(os.path.join(model_path,generator_weights))\n",
        "  discriminator.load_weights(os.path.join(model_path, discriminator_weights))\n",
        "\n",
        "\n",
        "bce_loss_fn = BinaryCrossentropy(from_logits=True, label_smoothing=0.1)\n",
        "discriminator_optimizer = Adam(learning_rate=0.00025, beta_1=0.5)\n",
        "generator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "\n",
        "def loss_D(real_logits, fake_logits):\n",
        "    real_loss = 0.5 * bce_loss_fn(ones_like(real_logits), real_logits)\n",
        "    fake_loss = 0.5 * bce_loss_fn(zeros_like(fake_logits), fake_logits)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "\n",
        "def loss_G(fake_logits):\n",
        "    loss = bce_loss_fn(ones_like(fake_logits), fake_logits)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def loss_D_real(real_logits):\n",
        "    real_loss = bce_loss_fn(ones_like(real_logits), real_logits)\n",
        "    return real_loss\n",
        "\n",
        "\n",
        "def loss_D_fake(fake_logits):\n",
        "    fake_loss = bce_loss_fn(zeros_like(fake_logits), fake_logits)\n",
        "    return fake_loss  \n",
        "\n",
        "@tf.function\n",
        "def training_step(images):\n",
        "    noise = normal(shape=[batch_size, latent_dim], mean=0, stddev=1)\n",
        "\n",
        "    # calculate the real discriminator loss \n",
        "    with tf.GradientTape() as real_tape:\n",
        "        discriminator_loss_real = loss_D_real(discriminator(images, training=True))\n",
        "        discriminator_gradients_real = real_tape.gradient(discriminator_loss_real, discriminator.trainable_variables)\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients_real, discriminator.trainable_variables))\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        fake_logits = discriminator(generator(noise, training=True), training=True)\n",
        "\n",
        "        discriminator_loss_fake = loss_D_fake(fake_logits)\n",
        "        generator_loss = loss_G(fake_logits)\n",
        "\n",
        "        discriminator_gradients_fake = disc_tape.gradient(discriminator_loss_fake, discriminator.trainable_variables)\n",
        "        generator_gradients = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
        "\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients_fake, discriminator.trainable_variables))\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "\n",
        "    return generator_loss, discriminator_loss_real, discriminator_loss_fake\n",
        "\n",
        "def save_generated_images(noise, epoch=None):\n",
        "    images = generator(noise)\n",
        "    images = tf.clip_by_value((images + 1) * 127.5, 0, 255).numpy()\n",
        "    if not os.path.isdir(\"training_images\"):\n",
        "      os.mkdir(\"training_images\")     \n",
        "    for i in range(16):\n",
        "        cv2.imwrite(f'training_images/image_number_{i}_ep_{epoch}.png',cv2.cvtColor(images[i], cv2.COLOR_RGB2BGR))        \n",
        "\n",
        "def train(epochs=30, save_every=3, steps=None):\n",
        "    batch_losses = {'g_loss': [], 'd_loss': []}\n",
        "    epoch_losses = {'g_loss': [], 'd_loss': []}\n",
        "    for ep in range(epochs):\n",
        "        running_loss = {'g_loss': [], 'd_loss': []}\n",
        "        for step, images in enumerate(image_dataset):\n",
        "            batch_g_loss, batch_d_loss_real, batch_d_loss_fake = training_step(images)\n",
        "            batch_d_loss = batch_d_loss_real + batch_d_loss_fake\n",
        "            running_loss['g_loss'].append(batch_g_loss.numpy())\n",
        "            running_loss['d_loss'].append(batch_d_loss.numpy())\n",
        "        print(f'||epoch {ep+1}/{epochs} step {step+1}/{steps}|G_LOSS : {batch_g_loss:.3f}|D_LOSS : {batch_d_loss:.3f}||')    \n",
        "        batch_losses['g_loss'].extend(running_loss['g_loss'])\n",
        "        batch_losses['d_loss'].extend(running_loss['d_loss'])\n",
        "        epoch_losses['g_loss'].append(np.mean(running_loss['g_loss']))\n",
        "        epoch_losses['d_loss'].append(np.mean(running_loss['d_loss']))\n",
        "        if (ep + 1) % save_every == 0:\n",
        "            print(f'||saving weights for epoch : {ep+1}||')\n",
        "            generator.save_weights(os.path.join(model_folders,f'generator_weights_{ep+1}.h5'))\n",
        "            discriminator.save_weights(os.path.join(model_folders,f'discriminator_weights_{ep+1}.h5'))\n",
        "            save_generated_images(display_noise, epoch=f'{ep+1}_{step+1}')\n",
        "    return batch_losses, epoch_losses\n",
        "\n",
        "total_epochs = 10 #@param {type:\"integer\"}\n",
        "save_every = 1 #@param {type:\"integer\"}\n",
        "\n",
        "batch_losses, epoch_losses = train(total_epochs, save_every, len(image_list)//batch_size) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcwJ4StDEuv4",
        "colab_type": "text"
      },
      "source": [
        "# Notes : \n",
        "\n",
        "### *save the colab file in your drive or in playground mode \n",
        "#### *for the augmentaion make sure you select the augmentaion flag then add augmentaion folder name \n",
        "### *This code is modified version of : [TFDCGAN](https://www.tensorflow.org/tutorials/generative/dcgan)\n",
        "### *learn more tips for DCGAN [Link](https://medium.com/intel-student-ambassadors/tips-on-training-your-gans-faster-and-achieve-better-results-9200354acaa5)\n",
        "### *For image height and width Have to be x^2\n",
        " \n"
      ]
    }
  ]
}